{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os, sys; sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from src.loadingdata.read_dataset import readData\n",
    "from src.features.data_preprocessing import preprocessData\n",
    "from src.visualization.visualize import visualizeData, DisplayCallback\n",
    "from src.modules.build_model import buildModel\n",
    "from src.modules.train_model import  trainModel\n",
    "from src.modules.predict_model import predictor\n",
    "from src.hyper_parameters.hps import get_hyper_paras\n",
    "from src.github_commands.git_utils import gitCommands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH,STEPS_PER_EPOCH,VALIDATION_STEPS,EPOCHS,VAL_SUBSPLITS,FINE_TUNE,model_dir,refRepoName,sourceRepoName,refRepoDir = get_hyper_paras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('../data/creditcard.csv.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"../data/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let see how features are distributed w.r.t., our target variable, which is \"Class\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = data.columns.values\n",
    "\n",
    "i = 0\n",
    "t0 = data.loc[data['Class'] == 0]\n",
    "t1 = data.loc[data['Class'] == 1]\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots(8,4,figsize=(16,28))\n",
    "\n",
    "for feature in var:\n",
    "    i += 1\n",
    "    plt.subplot(8,4,i)\n",
    "    sns.kdeplot(t0[feature], bw=0.5,label=\"Class = 0\")\n",
    "    sns.kdeplot(t1[feature], bw=0.5,label=\"Class = 1\")\n",
    "    plt.xlabel(feature, fontsize=12)\n",
    "    locs, labels = plt.xticks()\n",
    "    plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with this dataset, we need to bring all the variables in the same scale. But before that we will do a little more exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,10))\n",
    "plt.title('Credit Card Transactions features correlation plot')\n",
    "corr = data.corr()\n",
    "sns.heatmap(corr,xticklabels=corr.columns,yticklabels=corr.columns,linewidths=.1,cmap=\"Greens\",fmt='.1f',annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is pretty imbalanced as can be seen just below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Class\"].value_counts().plot(kind=\"bar\",color=\"red\")\n",
    "plt.title(\"Frequency of the target classes\", size=20)\n",
    "plt.xlabel(\"Target Labels\", size = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the exact frequency values for both the target labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.DataFrame(data[\"Class\"].value_counts())\n",
    "target.style.background_gradient(cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.iloc[1].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = np.bincount(target[:, 0])\n",
    "# print(\n",
    "#     \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
    "#         counts[1], 100 * float(counts[1]) / len(train_targets)\n",
    "#     )\n",
    "# )\n",
    "\n",
    "weight_for_0 = (1.0 / target.iloc[0].values[0])\n",
    "weight_for_1 = (1.0 / target.iloc[1].values[0])*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try to standardize all our input features and for that we will seperate the input from the output feature, so that it will be easy for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(columns=[\"Class\"])\n",
    "y=data[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=X.columns\n",
    "scaled_df = preprocessing.scale(X)\n",
    "scaled_df = pd.DataFrame(scaled_df,columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So by seeing the time and amount features, we can say that the features has been scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df[[\"Amount\",\"Time\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As here we are dealing with the problem of imbalanced dataset, so we will try to balance it using a technique called \"**SMOTE**\" which is the short form of **Synthetic Minority Over-sampling Technique**, this is another method of simple over-sampling technique, but here instead of just duplicating the minority the class, synthetic data are produced, so according to me it is much better compared to simple over-sampling, which just randomly duplicates the minority class to balance it. There is another method, by which we can solve this problem of unbalaced data, which is \"Down-Sampling\", but I am not a big fan of that technique cause there is a lot of data loss which happens while trying to achieve that.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data\n",
    "\n",
    "\n",
    "Now we will split the standardized dataset into train and test, and then do over-sampling on the training dataset, and then we will do the classification based on the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df, y, test_size = 0.30, random_state = 0, shuffle = True, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also let's check a few thing about the splitted data before we proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE\n",
    "\n",
    "\n",
    "Now we will start the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state = 33)\n",
    "X_train_new, y_train_new = sm.fit_resample(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will see whether it has been balanced or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_train_new).value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it is pretty much balanced now, and we can build our predictive model with it now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver = 'lbfgs')\n",
    "clf.fit(X_train_new, y_train_new)\n",
    "train_pred = clf.predict(X_train_new)\n",
    "test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy score for Training Dataset = ', accuracy_score(train_pred, y_train_new))\n",
    "print('Accuracy score for Testing Dataset = ', accuracy_score(test_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test, test_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix for Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.set(font_scale=1.2)\n",
    "sns.heatmap(cm, annot=True, fmt = 'g', cmap=\"Reds\", cbar = False)\n",
    "plt.xlabel(\"Predicted Label\", size = 18)\n",
    "plt.ylabel(\"True Label\", size = 18)\n",
    "plt.title(\"Confusion Matrix Plotting for Logistic Regression model\", size = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So from the above confusion matrix, we can see that the nummber of wrong classifications done for 0, which is \"no fraud\" is 2018 out of 85295, and number of wrong classification done for 1, which is \"Fraud happened\" is 13 out of 148, or in terms of percentages, let's see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage for 'no fraud' cases wrong classification using Logistic Regression is:\", (2018/85295)*100)\n",
    "print(\"Percentage for 'Fraud' cases wrong prediction Logistic Regression is:\", (13/148)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(X_train_new.shape[1], activation = 'relu', input_dim = X_train_new.shape[1]))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(units=128, kernel_initializer='uniform', input_dim=X_train_new.shape[1], activation='relu'),\n",
    "    Dense(units=18, kernel_initializer='uniform', activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(20, kernel_initializer='uniform', activation='relu'),\n",
    "    Dense(24, kernel_initializer='uniform', activation='relu'),\n",
    "    Dense(1, kernel_initializer='uniform', activation='sigmoid')\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters that we have used here are **Batch Normalization**, and **Dropout**. And the activation function we have used here for hidden layers are \"relu\", and for output, it is \"Sigmoid\" function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "]\n",
    "optimizer = keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(optimizer = optimizer, loss = 'binary_focal_crossentropy',metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To protect our model from overfitting, we will use early stop feature of tensorflow, which will once identify that the evaluation metric that we mentioned, if it stopped improving further, it will stop the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 10)\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=X_train_new, y=y_train_new, batch_size = 256, epochs=150,\n",
    "          validation_data=(X_test, y_test), verbose=1,\n",
    "          callbacks=[early_stop],class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_metrics=pd.DataFrame(model.history.history)\n",
    "evaluation_metrics.plot(figsize=(10,5))\n",
    "plt.title(\"Loss for both Training and Validation\", size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# y_pred = model.predict_classes(X_test)\n",
    "import numpy as np\n",
    "predict_x=model.predict(X_test) \n",
    "y_pred=np.argmax(predict_x,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_nn=confusion_matrix(y_test, y_pred)\n",
    "cm_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix for Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.set(font_scale=1.2)\n",
    "sns.heatmap(cm_nn, annot=True, fmt = 'g', cmap=\"winter\", cbar = False)\n",
    "plt.xlabel(\"Predicted Label\", size = 18)\n",
    "plt.ylabel(\"True Label\", size = 18)\n",
    "plt.title(\"Confusion Matrix Plotting for Neural Network model\", size = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if we compare this with the Logistic Regression model, the little problem here is that, it is doing very good prediction for the majority class, which is 0 or \"**No Fraud**\" cases, but for minority class, which is 1 or \"**Fraud**\" cases, it is performing a little less better than the Logistic Regression. But I guess with a little more hyperparamters tuning, the model will be able to perform better than the Logistic Regression even for **minority class**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
